{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initial Setup and Configuration\n",
        "\n",
        "This notebook sets up the Databricks environment and loads initial data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Databricks notebook source\n",
        "# MAGIC %md\n",
        "# MAGIC ## Step 1: Install Required Libraries\n",
        "# MAGIC \n",
        "# MAGIC Install all required Python packages.\n",
        "\n",
        "%pip install yfinance>=0.2.0\n",
        "%pip install alpha-vantage>=2.3.0\n",
        "%pip install fredapi>=0.5.0\n",
        "%pip install openai>=1.0.0\n",
        "%pip install anthropic>=0.18.0\n",
        "%pip install pydantic>=2.0.0\n",
        "%pip install python-dotenv>=1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAGIC %md\n",
        "# MAGIC ## Step 2: Configure API Keys\n",
        "# MAGIC \n",
        "# MAGIC Set up API keys from Databricks Secrets or environment variables.\n",
        "\n",
        "import os\n",
        "\n",
        "# Option 1: Use Databricks Secrets (Recommended)\n",
        "try:\n",
        "    openai_key = dbutils.secrets.get(scope=\"stocks_ai_secrets\", key=\"openai_api_key\")\n",
        "    os.environ['OPENAI_API_KEY'] = openai_key\n",
        "    print(\"✓ OpenAI API key loaded from secrets\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠ OpenAI key not found in secrets: {e}\")\n",
        "\n",
        "try:\n",
        "    alpha_vantage_key = dbutils.secrets.get(scope=\"stocks_ai_secrets\", key=\"alpha_vantage_api_key\")\n",
        "    os.environ['ALPHA_VANTAGE_API_KEY'] = alpha_vantage_key\n",
        "    print(\"✓ Alpha Vantage API key loaded from secrets\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Alpha Vantage key not found in secrets: {e}\")\n",
        "\n",
        "try:\n",
        "    fred_key = dbutils.secrets.get(scope=\"stocks_ai_secrets\", key=\"fred_api_key\")\n",
        "    os.environ['FRED_API_KEY'] = fred_key\n",
        "    print(\"✓ FRED API key loaded from secrets\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠ FRED key not found in secrets: {e}\")\n",
        "\n",
        "# Option 2: Use environment variables (if set on cluster)\n",
        "# Keys should already be in os.environ if set on cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAGIC %md\n",
        "# MAGIC ## Step 3: Set Up Python Path\n",
        "# MAGIC \n",
        "# MAGIC Update path to point to your repository.\n",
        "\n",
        "import sys\n",
        "\n",
        "# Update this path to your actual repository location\n",
        "# Option 1: If using Databricks Repos\n",
        "repo_path = '/Workspace/Repos/your-username/stocks-ai/stocks'\n",
        "\n",
        "# Option 2: If uploaded to workspace\n",
        "# repo_path = '/Workspace/Users/your-email@company.com/stocks'\n",
        "\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.append(repo_path)\n",
        "    print(f\"✓ Added {repo_path} to Python path\")\n",
        "else:\n",
        "    print(f\"✓ Path already configured: {repo_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAGIC %md\n",
        "# MAGIC ## Step 4: Test Basic Data Loading\n",
        "# MAGIC \n",
        "# MAGIC Test Yahoo Finance before full implementation.\n",
        "\n",
        "import yfinance as yf\n",
        "from datetime import date\n",
        "\n",
        "# Test Yahoo Finance\n",
        "print(\"Testing Yahoo Finance...\")\n",
        "ticker = yf.Ticker(\"AAPL\")\n",
        "info = ticker.info\n",
        "print(f\"✓ Company: {info.get('longName', 'N/A')}\")\n",
        "print(f\"✓ Sector: {info.get('sector', 'N/A')}\")\n",
        "print(f\"✓ Industry: {info.get('industry', 'N/A')}\")\n",
        "\n",
        "# Test price data\n",
        "hist = ticker.history(period=\"5d\")\n",
        "if not hist.empty:\n",
        "    print(f\"✓ Latest price: ${hist['Close'].iloc[-1]:.2f}\")\n",
        "    print(f\"✓ Data loaded successfully!\")\n",
        "else:\n",
        "    print(\"⚠ No price data available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAGIC %md\n",
        "# MAGIC ## Step 5: Load Fortune 100 Companies\n",
        "# MAGIC \n",
        "# MAGIC Load initial company master data.\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from datetime import datetime\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Fortune 100 companies (top 20 as example)\n",
        "fortune100_symbols = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\",\n",
        "    \"META\", \"TSLA\", \"BRK.B\", \"V\", \"JNJ\",\n",
        "    \"WMT\", \"PG\", \"MA\", \"UNH\", \"HD\",\n",
        "    \"DIS\", \"BAC\", \"ADBE\", \"NFLX\", \"CRM\"\n",
        "    # Add more as needed\n",
        "]\n",
        "\n",
        "# Load companies\n",
        "companies = []\n",
        "for symbol in fortune100_symbols:\n",
        "    try:\n",
        "        ticker = yf.Ticker(symbol)\n",
        "        info = ticker.info\n",
        "        \n",
        "        companies.append({\n",
        "            \"symbol\": symbol,\n",
        "            \"company_name\": info.get(\"longName\", symbol),\n",
        "            \"sector\": info.get(\"sector\", \"Unknown\"),\n",
        "            \"industry\": info.get(\"industry\", \"Unknown\"),\n",
        "            \"market_cap\": info.get(\"marketCap\"),\n",
        "            \"fortune_rank\": None,\n",
        "            \"added_date\": datetime.now(),\n",
        "            \"updated_date\": datetime.now()\n",
        "        })\n",
        "        print(f\"✓ Loaded {symbol}: {info.get('longName', symbol)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Failed to load {symbol}: {e}\")\n",
        "\n",
        "if companies:\n",
        "    df = spark.createDataFrame(companies)\n",
        "    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"stocks_ai.fortune100.companies\")\n",
        "    print(f\"\\n✓ Saved {len(companies)} companies to Delta table\")\n",
        "    df.show(truncate=False)\n",
        "else:\n",
        "    print(\"✗ No companies loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAGIC %md\n",
        "# MAGIC ## Step 6: Verify Setup\n",
        "# MAGIC \n",
        "# MAGIC Check that everything is configured correctly.\n",
        "\n",
        "# MAGIC %sql\n",
        "# MAGIC -- Verify companies table\n",
        "# MAGIC SELECT COUNT(*) as company_count FROM stocks_ai.fortune100.companies;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SETUP VERIFICATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "checks = {\n",
        "    \"Python path configured\": repo_path in sys.path,\n",
        "    \"OpenAI key available\": os.getenv('OPENAI_API_KEY') is not None,\n",
        "    \"Yahoo Finance works\": len(companies) > 0,\n",
        "    \"Delta table accessible\": True\n",
        "}\n",
        "\n",
        "for check, status in checks.items():\n",
        "    status_icon = \"✓\" if status else \"✗\"\n",
        "    print(f\"{status_icon} {check}\")\n",
        "\n",
        "# Verify Delta table\n",
        "try:\n",
        "    count = spark.sql(\"SELECT COUNT(*) as cnt FROM stocks_ai.fortune100.companies\").collect()[0]['cnt']\n",
        "    print(f\"✓ Companies in table: {count}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Delta table error: {e}\")\n",
        "\n",
        "if all(checks.values()):\n",
        "    print(\"\\n✅ Phase 1 Setup Complete!\")\n",
        "    print(\"You can now proceed to Phase 2: Core Infrastructure\")\n",
        "else:\n",
        "    print(\"\\n⚠️  Some checks failed. Please review the setup steps above.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
